{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "import preprocessor as p\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "import emoji\n",
    "from sklearn.metrics import *\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_Eval(Y_Actual,Y_pred):\n",
    "\n",
    "    TrueNegative=0\n",
    "    TruePositive=0\n",
    "    FalsePositive=0\n",
    "    FalseNegative=0\n",
    "    for i in range(len(Y_pred)):\n",
    "        #if the actual class is negative\n",
    "        if(Y_Actual[i]==\"fake\"):\n",
    "            \n",
    "            #if the predicited class is negative\n",
    "            if(Y_pred[i]==\"fake\"):\n",
    "                TrueNegative+=1\n",
    "                \n",
    "            #if the predicted class is positive\n",
    "            else:\n",
    "                FalsePositive+=1\n",
    "                \n",
    "        #if the actual class is positive\n",
    "        else:\n",
    "            #if the predicited class is positive\n",
    "            if(Y_pred[i]==\"real\"):\n",
    "                TruePositive+=1\n",
    "                \n",
    "            #if the predicited class is negative\n",
    "            else:\n",
    "                FalseNegative+=1\n",
    "\n",
    "    Confusion_Matrix=[[TrueNegative,FalsePositive],[FalseNegative,TruePositive]]\n",
    "    \n",
    "    Confusion_Matrix=pd.DataFrame(Confusion_Matrix,columns=['Actual Negative','Actual Positive'])\n",
    "    \n",
    "    Confusion_Matrix.rename(index={0: \"Predicted Negative\", 1: \"Predicted Positive\"},inplace=True)\n",
    "    \n",
    "    MyPrecision=TruePositive/(TruePositive+FalsePositive)\n",
    "\n",
    "    MyRecall=TruePositive/(TruePositive+FalseNegative)\n",
    "    \n",
    "    MyAccuracy=(TruePositive+TrueNegative)/(TruePositive+TrueNegative+FalseNegative+FalsePositive)\n",
    "    \n",
    "    MyF1score= 2*(MyPrecision*MyRecall)/(MyPrecision+MyRecall)\n",
    "    \n",
    "    MyPrecisionZero=TrueNegative/(TrueNegative+FalseNegative)\n",
    "\n",
    "    MyRecallZero=TrueNegative/(TrueNegative+FalsePositive)\n",
    "    \n",
    "    \n",
    "    MyF1scoreZero= 2*(MyPrecisionZero*MyRecallZero)/(MyPrecisionZero+MyRecallZero)\n",
    "\n",
    "    \n",
    "    print(\"-----------------\")\n",
    "    print(\"Accuracy:\",MyAccuracy)\n",
    "    print(\"-----------------\")\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(\"For the Positive CLass, Label:4\")\n",
    "    print(\"-----------------\")\n",
    "    print(\"Precision:\",MyPrecision)\n",
    "\n",
    "    print(\"-----------------\")\n",
    "    print(\"Recall:\",MyRecall)\n",
    "\n",
    "    print(\"-----------------\")\n",
    "    print(\"F1 Score:\",MyF1score)\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(\"For the Negative CLass, Label:0\")\n",
    "\n",
    "    print(\"-----------------\")\n",
    "    print(\"Precision:\",MyPrecisionZero)\n",
    "\n",
    "    print(\"-----------------\")\n",
    "    print(\"Recall:\",MyRecallZero)\n",
    "\n",
    "    print(\"-----------------\")\n",
    "    print(\"F1 Score:\",MyF1scoreZero)\n",
    "\n",
    "    print()\n",
    "    print(\"--------\")\n",
    "    print(\"Macro Average F1\",(MyF1score+MyF1scoreZero)/2)\n",
    "    print(\"-----------------\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(Confusion_Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_caller(Tweets_List):\n",
    "    stop_words_list=stopwords.words('english')\n",
    "    for i in (range(len(Tweets_List))):\n",
    "        Tweets_List[i]=preprocess_text(Tweets_List[i],stop_words_list=stop_words_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(tweet, flag_stemm=True, flag_lemm=True, stop_words_list=None):\n",
    "#     print(tweet)\n",
    "    tweet=emoji.demojize(tweet)\n",
    "    tweet=tweet.replace(\":\",\" \")\n",
    "#     print(tweet)\n",
    "#     tweet=p.clean(tweet)\n",
    "    ## clean (convert to lowercase and remove punctuations and characters and then strip and remove url)\n",
    "    tweet = re.sub(r'[^\\w\\s]', '', str(tweet).lower().strip())\n",
    "#     tweet = re.sub(r'19', 'Z', str(tweet).lower().strip())\n",
    "#     tweet = re.sub(r'[0-9]+k*', ' X ', str(tweet).lower().strip())    \n",
    "#     tweet = re.sub(r'[^\\w\\s]', '', str(tweet).lower().strip())\n",
    "    ## Tokenize (convert from string to list) and remove the stop words\n",
    "#     print(tweet)\n",
    "\n",
    "    tokenize_tweet = tweet.split()\n",
    "\n",
    "    if stop_words_list is not None:\n",
    "        tokenize_tweet = [word for word in tokenize_tweet if word not in stop_words_list]\n",
    "\n",
    "\n",
    "    ## Stemming (remove -ing, -ly, ...)\n",
    "    if flag_stemm == True:\n",
    "        ps = nltk.stem.porter.PorterStemmer()\n",
    "        tokenize_tweet = [ps.stem(word) for word in tokenize_tweet]\n",
    "\n",
    "    ## Lemmatisation (convert the word into root word)\n",
    "    if flag_lemm == True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        tokenize_tweet = [lem.lemmatize(word) for word in tokenize_tweet]\n",
    "#     print(tokenize_tweet)\n",
    "    ## back to string from list\n",
    "    tweet = \" \".join(tokenize_tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLength(GivenTweets):\n",
    "    ret=np.zeros(len(GivenTweets))\n",
    "    for i in (range(len(GivenTweets))):\n",
    "        tweet=GivenTweets[i]\n",
    "        ret[i] = len(tweet)\n",
    "    return ret\n",
    "def getAvgWord(GivenTweets):\n",
    "    \n",
    "    ret=np.zeros(len(GivenTweets))\n",
    "    for i in (range(len(GivenTweets))):\n",
    "        tweet=GivenTweets[i].split()\n",
    "        cnt = 0\n",
    "        add = 0\n",
    "        for j in range(len(tweet)):\n",
    "            cnt+=1\n",
    "            add+= len(tweet[j])\n",
    "        ret[i] = add/cnt\n",
    "    return ret\n",
    "def getSpecial(GivenTweets):\n",
    "    ret=np.zeros(len(GivenTweets))\n",
    "    for i in (range(len(GivenTweets))):\n",
    "        tweet=GivenTweets[i].split()\n",
    "        cnt = 0\n",
    "        for j in range(len(tweet)):\n",
    "            if(tweet[j]=='X'):\n",
    "                cnt+=1\n",
    "        ret[i] = cnt\n",
    "    return ret\n",
    "    \n",
    "def vader( GivenTweets):\n",
    "    obj = SentimentIntensityAnalyzer()\n",
    "    Comp_vader = np.zeros(len(GivenTweets))\n",
    "    for i in range(len(GivenTweets)):\n",
    "        sentiment_dict = obj.polarity_scores(GivenTweets[i])\n",
    "        Comp_vader[i]=sentiment_dict['compound']\n",
    "    return(Comp_vader)\n",
    "def FuncAllCapsCount( GivenTweets):\n",
    "    # Function to get All caps count from the tweets\n",
    "    # pass tweets as it is\n",
    "\n",
    "    AllCapsCount = np.zeros(len(GivenTweets))\n",
    "    for i in range(len(GivenTweets)):\n",
    "        tweet = nltk.word_tokenize(GivenTweets[i])\n",
    "        for word in tweet:\n",
    "            if(word!=\"I\" and word != \"USER\" and word != \"URL\" and re.match(\"^[A-Z]+$\",word)):\n",
    "                AllCapsCount[i] += 1\n",
    "\n",
    "    return AllCapsCount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training=pd.DataFrame(pd.read_csv(\"Constraint_English_Train - Sheet1.csv\"))\n",
    "df_training.drop(columns=\"id\",inplace=True)\n",
    "# df_training\n",
    "df_training['tweet_original']=df_training['tweet']\n",
    "preprocess_text_caller(df_training['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation=pd.DataFrame(pd.read_csv(\"Constraint_English_Val - Sheet1.csv\"))\n",
    "df_validation.drop(columns=\"id\",inplace=True)\n",
    "# df_validation\n",
    "df_validation['tweet_original']=df_validation['tweet']\n",
    "preprocess_text_caller(df_validation['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-fb9ae317fd00>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Tweets_List[i]=preprocess_text(Tweets_List[i],stop_words_list=stop_words_list)\n"
     ]
    }
   ],
   "source": [
    "df_test=pd.DataFrame(pd.read_csv(\"Constraint_English_Test - Sheet1.csv\"))\n",
    "# df_test\n",
    "df_test['tweet_original']=df_test['tweet']\n",
    "preprocess_text_caller(df_test['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2),min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train_ngrams=vectorizer.fit_transform(df_training.tweet)\n",
    "vectorizer.fit_transform(list(df_training.tweet) + list(df_validation.tweet) +list(df_test.tweet))\n",
    "Train_ngrams=vectorizer.transform(df_training.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "Validation_f=pd.DataFrame(FuncAllCapsCount(df_validation.tweet))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "Validation_ngrams=vectorizer.transform(df_validation.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2140x28361 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 50472 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Validation_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_ngrams=vectorizer.transform(df_test.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "clf.fit(Train_ngrams,df_training[\"label\"])\n",
    "y_pred_rf=clf.predict(Validation_ngrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9214293769160768"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred_rf,df_validation[\"label\"],average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1_score(y_pred,df_validation[\"label\"],average=\"macro\")\n",
    "# func_Eval(y_pred,df_validation[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "clf = make_pipeline(StandardScaler(with_mean=False), SVC(gamma='auto',kernel=\"sigmoid\"))\n",
    "clf.fit(Train_ngrams,df_training[\"label\"])\n",
    "y_pred_svm=clf.predict(Validation_ngrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9420009074925841"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred_svm,df_validation[\"label\"],average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func_Eval(y_pred_svm,df_validation[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0)\n",
    "clf.fit(Train_ngrams,df_training[\"label\"])\n",
    "y_pred_log=clf.predict(Validation_ngrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9199220797238565"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred_log,df_validation[\"label\"],average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func_Eval(y_pred_log,df_validation[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9302788169483306"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf2 = MLPClassifier(random_state=1, max_iter=300,verbose=True,activation=\"logistic\",solver=\"lbfgs\")\n",
    "clf2.fit(Train_ngrams,df_training[\"label\"])\n",
    "y_pred_mlp=clf2.predict(Validation_ngrams)\n",
    "f1_score(y_pred_mlp,df_validation[\"label\"],average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9420163689695801"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "svc = make_pipeline(StandardScaler(with_mean=False), SVC(gamma='auto',kernel=\"sigmoid\"))\n",
    "bag = BaggingClassifier(svc,n_estimators=50, random_state=0,n_jobs=-1)\n",
    "bag.fit(Train_ngrams,df_training[\"label\"])\n",
    "y_pred_bag=bag.predict(Validation_ngrams)\n",
    "f1_score(y_pred_bag,df_validation[\"label\"],average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=[]\n",
    "\n",
    "for i in range(len(y_pred_log)):\n",
    "    if(y_pred_svm[i]==y_pred_mlp[i]):\n",
    "        y.append(y_pred_svm[i])\n",
    "    elif(y_pred_svm[i]==y_pred_rf[i]):\n",
    "        y.append(y_pred_svm[i])\n",
    "    elif(y_pred_rf[i]==y_pred_mlp[i]):\n",
    "        y.append(y_pred_log[i])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9354368180661479"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y,df_validation[\"label\"],average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the shortened URL in its entirety: abc\n"
     ]
    },
    {
     "ename": "MissingSchema",
     "evalue": "Invalid URL 'abc': No schema supplied. Perhaps you meant http://abc?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingSchema\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7cf92f6f5c0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mshorturl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the shortened URL in its entirety: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshorturl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m print(\"\"\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         )\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mprep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0mproxies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproxies\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mprepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPreparedRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m         p.prepare(\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_cookies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcookies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare_url\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_native_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMissingSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMissingSchema\u001b[0m: Invalid URL 'abc': No schema supplied. Perhaps you meant http://abc?"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "\n",
    "shorturl = input(\"Enter the shortened URL in its entirety: \")\n",
    "r = requests.get(shorturl)\n",
    "\n",
    "print(\"\"\"\n",
    "The shortened URL forwards to:\n",
    "\n",
    "    %s\n",
    "\"\"\" % r.url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "websites_train=[]\n",
    "websites_valid=[]\n",
    "websites_test=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6420/6420 [00:00<00:00, 26062.97it/s]\n",
      "100%|██████████| 2140/2140 [00:00<00:00, 28030.05it/s]\n",
      "100%|██████████| 2140/2140 [00:00<00:00, 28751.85it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(df_training.tweet_original))):\n",
    "    tweet=df_training.tweet_original[i].split(\" \")\n",
    "#     print(tweet)\n",
    "    for word in tweet:\n",
    "        if(re.match(\"http\",word)):\n",
    "            websites_train.append([i,word])\n",
    "for i in tqdm(range(len(df_validation.tweet_original))):\n",
    "    tweet=df_validation.tweet_original[i].split(\" \")\n",
    "#     print(tweet)\n",
    "    for word in tweet:\n",
    "        if(re.match(\"http\",word)):\n",
    "            websites_valid.append([i,word])\n",
    "for i in tqdm(range(len(df_test.tweet_original))):\n",
    "    tweet=df_test.tweet_original[i].split(\" \")\n",
    "#     print(tweet)\n",
    "    for word in tweet:\n",
    "        if(re.match(\"http\",word)):\n",
    "            websites_test.append([i,word])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1464 4314 1459\n"
     ]
    }
   ],
   "source": [
    "print(len(websites_test),len(websites_train),len(websites_valid))\n",
    "# websites_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 63/4314 [00:08<14:22,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1146/4314 [06:36<6:17:45,  7.15s/it]"
     ]
    }
   ],
   "source": [
    "# len(websites)\n",
    "from requests.exceptions import SSLError,ConnectionError\n",
    "for i in tqdm(range(len(websites_train))):\n",
    "    if(\"t.co\" in websites_train[i][1]):\n",
    "        try:\n",
    "            websites_train[i][1]=requests.get(websites_train[i][1]).url\n",
    "        except SSLError:\n",
    "            print(\"error\")\n",
    "            continue\n",
    "        except ConnectionError:\n",
    "            continue\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file=open(\"websites_train\",\"wb\")\n",
    "pickle.dump(websites_train,file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 174/1459 [06:05<49:08,  2.29s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 1094/1459 [46:38<09:00,  1.48s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1459/1459 [58:12<00:00,  2.39s/it]\n"
     ]
    }
   ],
   "source": [
    "# len(websites)\n",
    "from requests.exceptions import SSLError\n",
    "for i in tqdm(range(len(websites_valid))):\n",
    "    try:\n",
    "        websites_valid[i][1]=requests.get(websites_valid[i][1]).url\n",
    "    except SSLError:\n",
    "        print(\"error\")\n",
    "        continue\n",
    "    except :\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file=open(\"websites_valid\",\"wb\")\n",
    "pickle.dump(websites_valid,file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 658/1464 [33:08<24:42,  1.84s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1464/1464 [1:06:40<00:00,  2.73s/it]  \n"
     ]
    }
   ],
   "source": [
    "from requests.exceptions import SSLError\n",
    "for i in tqdm(range(len(websites_test))):\n",
    "\n",
    "    try:\n",
    "        websites_test[i][1]=requests.get(websites_test[i][1]).url\n",
    "    except SSLError:\n",
    "        print(\"error\")\n",
    "        continue\n",
    "    except :\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file=open(\"websites_test\",\"wb\")\n",
    "pickle.dump(websites_test,file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "web=set()\n",
    "for i in websites_train:\n",
    "    \n",
    "    web.add(i[1][:min(22,len(i[1]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'http://inbministry.blo',\n",
       " 'http://revenue.delhi.g',\n",
       " 'http://www.msn.com/en-',\n",
       " 'https://accounts.googl',\n",
       " 'https://amp.cnn.com/cn',\n",
       " 'https://arogya.maharas',\n",
       " 'https://blog.covidactn',\n",
       " 'https://blog.rootclaim',\n",
       " 'https://bmjopen.bmj.co',\n",
       " 'https://businessinthen',\n",
       " 'https://ccc19.org/',\n",
       " 'https://consultqd.clev',\n",
       " 'https://coronavirus-re',\n",
       " 'https://coronavirus.ma',\n",
       " 'https://covid19.govt.n',\n",
       " 'https://covid19.ncdc.g',\n",
       " 'https://covid19.telang',\n",
       " 'https://covid19respons',\n",
       " 'https://covidactnow.or',\n",
       " 'https://covidtracking.',\n",
       " 'https://crooked.com/ar',\n",
       " 'https://dailyinterlake',\n",
       " 'https://docs.google.co',\n",
       " 'https://edition.cnn.co',\n",
       " 'https://emedicine.meds',\n",
       " 'https://en.m.wikipedia',\n",
       " 'https://erj.ersjournal',\n",
       " 'https://experience.arc',\n",
       " 'https://forbetterscien',\n",
       " 'https://ghpp.de/en/pro',\n",
       " 'https://gisgmda.maps.a',\n",
       " 'https://gujcovid19.guj',\n",
       " 'https://health.odisha.',\n",
       " 'https://hoops227.biz/',\n",
       " 'https://hoops227.shop/',\n",
       " 'https://ilcuk.org.uk/w',\n",
       " 'https://inbministry.bl',\n",
       " 'https://investors.mode',\n",
       " 'https://j-idea.github.',\n",
       " 'https://joebiden.com/C',\n",
       " 'https://joebiden.com/b',\n",
       " 'https://joebiden.com/c',\n",
       " 'https://joebiden.com/m',\n",
       " 'https://khn.org/news/t',\n",
       " 'https://mailchi.mp/a9e',\n",
       " 'https://mailchi.mp/pol',\n",
       " 'https://medium.com/@Jo',\n",
       " 'https://mixlr.com/hitf',\n",
       " 'https://ncdc.gov.ng/ne',\n",
       " 'https://ncdc.gov.ng/re',\n",
       " 'https://ncdc.gov.ng/th',\n",
       " 'https://news.sky.com/s',\n",
       " 'https://news.sky.com/w',\n",
       " 'https://news.yahoo.com',\n",
       " 'https://newschecker.in',\n",
       " 'https://newsfactsnetwo',\n",
       " 'https://newsfromwales.',\n",
       " 'https://newsthump.com/',\n",
       " 'https://nitp.ncdc.gov.',\n",
       " 'https://nnn.ng/nationa',\n",
       " 'https://north-wales-bu',\n",
       " 'https://nypost.com/202',\n",
       " 'https://omaha.com/live',\n",
       " 'https://onlinelibrary.',\n",
       " 'https://patents.justia',\n",
       " 'https://pennhills.org/',\n",
       " 'https://pharmanews.lin',\n",
       " 'https://pib.gov.in/Pre',\n",
       " 'https://portal.ct.gov/',\n",
       " 'https://public.tableau',\n",
       " 'https://pubmed.ncbi.nl',\n",
       " 'https://punchng.com/co',\n",
       " 'https://reference.meds',\n",
       " 'https://riverheadlocal',\n",
       " 'https://science.scienc',\n",
       " 'https://sciencejournal',\n",
       " 'https://shop.newsthump',\n",
       " 'https://smebusinessnew',\n",
       " 'https://sputniknews.co',\n",
       " 'https://t.co/0D99fLmey',\n",
       " 'https://t.co/0esau03IG',\n",
       " 'https://t.co/0q7VQP%E2',\n",
       " 'https://t.co/0t6Fshc3P',\n",
       " 'https://t.co/0vhHD4uFv',\n",
       " 'https://t.co/11CDwiQVb',\n",
       " 'https://t.co/17jMJBxJx',\n",
       " 'https://t.co/25nXiRzAW',\n",
       " 'https://t.co/2RvG3dwBK',\n",
       " 'https://t.co/2Xjim3Gai',\n",
       " 'https://t.co/2xlF9MccF',\n",
       " 'https://t.co/3C6vJxUTA',\n",
       " 'https://t.co/3Ei1hY2Sp',\n",
       " 'https://t.co/3fUMNKjuF',\n",
       " 'https://t.co/3v15grreJ',\n",
       " 'https://t.co/441ntP6EU',\n",
       " 'https://t.co/4Ku7nKLZC',\n",
       " 'https://t.co/4Z3Xv6Pru',\n",
       " 'https://t.co/4aj6MR4uO',\n",
       " 'https://t.co/5ODocrGOA',\n",
       " 'https://t.co/5WF5Qm4yd',\n",
       " 'https://t.co/6PRkBpcxf',\n",
       " 'https://t.co/6gr7tHYHJ',\n",
       " 'https://t.co/6yJdzuOdb',\n",
       " 'https://t.co/71ufv5o6O',\n",
       " 'https://t.co/8CKfrp9sD',\n",
       " 'https://t.co/98jmUt3IG',\n",
       " 'https://t.co/9ZN2zYTau',\n",
       " 'https://t.co/AUGYoqDMv',\n",
       " 'https://t.co/BHqCzO5GF',\n",
       " 'https://t.co/BSgsPiqW0',\n",
       " 'https://t.co/Bg0WDUndU',\n",
       " 'https://t.co/CEcelDa6H',\n",
       " 'https://t.co/D1T5mI712',\n",
       " 'https://t.co/DPmlworYg',\n",
       " 'https://t.co/DYojLfjhy',\n",
       " 'https://t.co/DdiQujSVI',\n",
       " 'https://t.co/DmfPOAPMj',\n",
       " 'https://t.co/DmfPOB7nb',\n",
       " 'https://t.co/Dpn350BZr',\n",
       " 'https://t.co/ECKkYQ3d4',\n",
       " 'https://t.co/EE7ci7LX3',\n",
       " 'https://t.co/EQtDgetVe',\n",
       " 'https://t.co/FH1GIhBZm',\n",
       " 'https://t.co/FQhg5M5xr',\n",
       " 'https://t.co/Fkuf7LPgB',\n",
       " 'https://t.co/Ft6cgmaMP',\n",
       " 'https://t.co/G0ea6I4E4',\n",
       " 'https://t.co/G8dUIQxiW',\n",
       " 'https://t.co/GKZV8vsPC',\n",
       " 'https://t.co/GRdRMdcWt',\n",
       " 'https://t.co/GUDbPY0X9',\n",
       " 'https://t.co/Ga2u5k439',\n",
       " 'https://t.co/H8NS2GBCc',\n",
       " 'https://t.co/H8NS2GTd4',\n",
       " 'https://t.co/ICR6oj4q1',\n",
       " 'https://t.co/IgH6uA8oH',\n",
       " 'https://t.co/Iw21OtZZc',\n",
       " 'https://t.co/J3Txu3riW',\n",
       " 'https://t.co/JoJssYrK0',\n",
       " 'https://t.co/KSQmpTAx2',\n",
       " 'https://t.co/KuLXWPdC1',\n",
       " 'https://t.co/L54PUk1lm',\n",
       " 'https://t.co/MCP09UDSP',\n",
       " 'https://t.co/MIzuS0LDn',\n",
       " 'https://t.co/MmRHhZ1Si',\n",
       " 'https://t.co/NFXhO4sAG',\n",
       " 'https://t.co/NJ2bfA6QP',\n",
       " 'https://t.co/NKs%E2%80',\n",
       " 'https://t.co/OVro238b8',\n",
       " 'https://t.co/Pg05bJ6I2',\n",
       " 'https://t.co/QV6qLVJhc',\n",
       " 'https://t.co/S8KeeOvNX',\n",
       " 'https://t.co/SVoIDrIF7',\n",
       " 'https://t.co/Se9PmcEcK',\n",
       " 'https://t.co/SlDrVXXfC',\n",
       " 'https://t.co/TV9jeTe0o',\n",
       " 'https://t.co/ToKRSVyLH',\n",
       " 'https://t.co/ULBSHv89O',\n",
       " 'https://t.co/Uwm8wZFkt',\n",
       " 'https://t.co/Uzvo7Z9Kx',\n",
       " 'https://t.co/VJ6DDNlas',\n",
       " 'https://t.co/VOKbZil9o',\n",
       " 'https://t.co/W3u2szgQe',\n",
       " 'https://t.co/Wq0UFOUPq',\n",
       " 'https://t.co/Wytp7O8Wg',\n",
       " 'https://t.co/XXPpWB23S',\n",
       " 'https://t.co/Xa1qKwzJh',\n",
       " 'https://t.co/YDHvl06N4',\n",
       " 'https://t.co/YiysTm1eF',\n",
       " 'https://t.co/Z9K0ShXJ1',\n",
       " 'https://t.co/Za5195Kas',\n",
       " 'https://t.co/ZjeKiqG5j',\n",
       " 'https://t.co/ZjeKiqous',\n",
       " 'https://t.co/a70fp6NOs',\n",
       " 'https://t.co/aj8a3arXi',\n",
       " 'https://t.co/bUyobRpOe',\n",
       " 'https://t.co/bihJ3xEM1',\n",
       " 'https://t.co/bynbDWi0g',\n",
       " 'https://t.co/c4F0aouML',\n",
       " 'https://t.co/dTvhftTxu',\n",
       " 'https://t.co/eLn38IAOP',\n",
       " 'https://t.co/eUOPul7RC',\n",
       " 'https://t.co/esoLo6GPG',\n",
       " 'https://t.co/f56xtoek3',\n",
       " 'https://t.co/fCxlvca0B',\n",
       " 'https://t.co/fEGMDOBt0',\n",
       " 'https://t.co/g7WsFWJdD',\n",
       " 'https://t.co/g9sT0JqtE',\n",
       " 'https://t.co/gGpYiwsgM',\n",
       " 'https://t.co/gUc5Pa2v5',\n",
       " 'https://t.co/hzHCrPrfN',\n",
       " 'https://t.co/iH2iRfg30',\n",
       " 'https://t.co/iKeLEWOqg',\n",
       " 'https://t.co/iOQv5OMdK',\n",
       " 'https://t.co/inSgagJeD',\n",
       " 'https://t.co/jcnPAkQpt',\n",
       " 'https://t.co/jkWwZTfWS',\n",
       " 'https://t.co/jkWwZTxyh',\n",
       " 'https://t.co/jyED1trjI',\n",
       " 'https://t.co/k5GuyJX2R',\n",
       " 'https://t.co/kg06tsWqr',\n",
       " 'https://t.co/l3eipKB6I',\n",
       " 'https://t.co/l3eipKjvj',\n",
       " 'https://t.co/lVZEjLOXm',\n",
       " 'https://t.co/lhYaTUON4',\n",
       " 'https://t.co/lmR9%E2%8',\n",
       " 'https://t.co/lxWMe4NUB',\n",
       " 'https://t.co/mAtuWWiT8',\n",
       " 'https://t.co/mKozTIhdK',\n",
       " 'https://t.co/mMPpxFUSy',\n",
       " 'https://t.co/mXDerodDR',\n",
       " 'https://t.co/mhm9gxCn3',\n",
       " 'https://t.co/n0QVAReII',\n",
       " 'https://t.co/nhTozU9qs',\n",
       " 'https://t.co/nmkWTkgrK',\n",
       " 'https://t.co/nrIieMNJU',\n",
       " 'https://t.co/ochY3fxe5',\n",
       " 'https://t.co/pN20Dpfd2',\n",
       " 'https://t.co/q1dtcXUKi',\n",
       " 'https://t.co/qKkt9oEm7',\n",
       " 'https://t.co/qOJIH4fvz',\n",
       " 'https://t.co/qp7dmrWVv',\n",
       " 'https://t.co/qpYN3dSJL',\n",
       " 'https://t.co/qymgi29Hu',\n",
       " 'https://t.co/rGGoSYmo3',\n",
       " 'https://t.co/rSkIkgkT4',\n",
       " 'https://t.co/rpkjdMZKe',\n",
       " 'https://t.co/s5KmREVXc',\n",
       " 'https://t.co/sB0kheLLU',\n",
       " 'https://t.co/seM7eTf6Q',\n",
       " 'https://t.co/tCpn0K7Ko',\n",
       " 'https://t.co/tLIlhG9oG',\n",
       " 'https://t.co/tnPX5fnVG',\n",
       " 'https://t.co/tqIMHdoax',\n",
       " 'https://t.co/tt49zOEC8',\n",
       " 'https://t.co/tt49zOn1h',\n",
       " 'https://t.co/uArGZTrH5',\n",
       " 'https://t.co/uYBfzUWVU',\n",
       " 'https://t.co/unpwzlB7x',\n",
       " 'https://t.co/v0oLb32GK',\n",
       " 'https://t.co/vAEXTXPs8',\n",
       " 'https://t.co/vLdiswtey',\n",
       " 'https://t.co/vWVKebacN',\n",
       " 'https://t.co/vevNzlxfr',\n",
       " 'https://t.co/vuYx19NZP',\n",
       " 'https://t.co/vuYx19woY',\n",
       " 'https://t.co/wGrCoNVd9',\n",
       " 'https://t.co/wbvgIg9Yc',\n",
       " 'https://t.co/wiuFBKR3U',\n",
       " 'https://t.co/z3oVIHBir',\n",
       " 'https://t.co/z5kkXpqkY',\n",
       " 'https://t.co/zP4VYlo0P',\n",
       " 'https://thebeaverton.c',\n",
       " 'https://theflashtoday.',\n",
       " 'https://thehill.com/ho',\n",
       " 'https://theweek.com/sp',\n",
       " 'https://thisisreno.com',\n",
       " 'https://time.com/58128',\n",
       " 'https://time.com/58365',\n",
       " 'https://timesofindia.i',\n",
       " 'https://twitter.com/3S',\n",
       " 'https://twitter.com/96',\n",
       " 'https://twitter.com/AB',\n",
       " 'https://twitter.com/AN',\n",
       " 'https://twitter.com/AZ',\n",
       " 'https://twitter.com/Aa',\n",
       " 'https://twitter.com/Ad',\n",
       " 'https://twitter.com/Ag',\n",
       " 'https://twitter.com/Aj',\n",
       " 'https://twitter.com/Al',\n",
       " 'https://twitter.com/Am',\n",
       " 'https://twitter.com/An',\n",
       " 'https://twitter.com/Ar',\n",
       " 'https://twitter.com/As',\n",
       " 'https://twitter.com/BA',\n",
       " 'https://twitter.com/Be',\n",
       " 'https://twitter.com/Bi',\n",
       " 'https://twitter.com/By',\n",
       " 'https://twitter.com/CA',\n",
       " 'https://twitter.com/CD',\n",
       " 'https://twitter.com/CN',\n",
       " 'https://twitter.com/CO',\n",
       " 'https://twitter.com/Ch',\n",
       " 'https://twitter.com/Cl',\n",
       " 'https://twitter.com/Co',\n",
       " 'https://twitter.com/DD',\n",
       " 'https://twitter.com/DG',\n",
       " 'https://twitter.com/Da',\n",
       " 'https://twitter.com/De',\n",
       " 'https://twitter.com/Dr',\n",
       " 'https://twitter.com/EL',\n",
       " 'https://twitter.com/Fa',\n",
       " 'https://twitter.com/GH',\n",
       " 'https://twitter.com/Ga',\n",
       " 'https://twitter.com/Go',\n",
       " 'https://twitter.com/Gu',\n",
       " 'https://twitter.com/HH',\n",
       " 'https://twitter.com/HI',\n",
       " 'https://twitter.com/He',\n",
       " 'https://twitter.com/Hi',\n",
       " 'https://twitter.com/Hu',\n",
       " 'https://twitter.com/IC',\n",
       " 'https://twitter.com/IG',\n",
       " 'https://twitter.com/Im',\n",
       " 'https://twitter.com/Ja',\n",
       " 'https://twitter.com/Ji',\n",
       " 'https://twitter.com/Jo',\n",
       " 'https://twitter.com/Ka',\n",
       " 'https://twitter.com/Ke',\n",
       " 'https://twitter.com/Kh',\n",
       " 'https://twitter.com/Kr',\n",
       " 'https://twitter.com/LC',\n",
       " 'https://twitter.com/LF',\n",
       " 'https://twitter.com/Lo',\n",
       " 'https://twitter.com/Lu',\n",
       " 'https://twitter.com/MR',\n",
       " 'https://twitter.com/MS',\n",
       " 'https://twitter.com/Ma',\n",
       " 'https://twitter.com/Me',\n",
       " 'https://twitter.com/Mo',\n",
       " 'https://twitter.com/NC',\n",
       " 'https://twitter.com/NP',\n",
       " 'https://twitter.com/Na',\n",
       " 'https://twitter.com/Ne',\n",
       " 'https://twitter.com/Of',\n",
       " 'https://twitter.com/Op',\n",
       " 'https://twitter.com/PB',\n",
       " 'https://twitter.com/PI',\n",
       " 'https://twitter.com/Pa',\n",
       " 'https://twitter.com/Pe',\n",
       " 'https://twitter.com/Pi',\n",
       " 'https://twitter.com/Po',\n",
       " 'https://twitter.com/Pr',\n",
       " 'https://twitter.com/Pu',\n",
       " 'https://twitter.com/Qu',\n",
       " 'https://twitter.com/RU',\n",
       " 'https://twitter.com/Ra',\n",
       " 'https://twitter.com/Ri',\n",
       " 'https://twitter.com/Rn',\n",
       " 'https://twitter.com/Ro',\n",
       " 'https://twitter.com/SM',\n",
       " 'https://twitter.com/Sa',\n",
       " 'https://twitter.com/Sh',\n",
       " 'https://twitter.com/Si',\n",
       " 'https://twitter.com/Sk',\n",
       " 'https://twitter.com/So',\n",
       " 'https://twitter.com/Su',\n",
       " 'https://twitter.com/Th',\n",
       " 'https://twitter.com/Ti',\n",
       " 'https://twitter.com/To',\n",
       " 'https://twitter.com/Tu',\n",
       " 'https://twitter.com/Tw',\n",
       " 'https://twitter.com/Uj',\n",
       " 'https://twitter.com/Ul',\n",
       " 'https://twitter.com/Us',\n",
       " 'https://twitter.com/VD',\n",
       " 'https://twitter.com/Va',\n",
       " 'https://twitter.com/Ve',\n",
       " 'https://twitter.com/Vi',\n",
       " 'https://twitter.com/WH',\n",
       " 'https://twitter.com/Xp',\n",
       " 'https://twitter.com/Ya',\n",
       " 'https://twitter.com/_C',\n",
       " 'https://twitter.com/_P',\n",
       " 'https://twitter.com/_V',\n",
       " 'https://twitter.com/_s',\n",
       " 'https://twitter.com/ad',\n",
       " 'https://twitter.com/ak',\n",
       " 'https://twitter.com/al',\n",
       " 'https://twitter.com/am',\n",
       " 'https://twitter.com/an',\n",
       " 'https://twitter.com/ap',\n",
       " 'https://twitter.com/as',\n",
       " 'https://twitter.com/at',\n",
       " 'https://twitter.com/ay',\n",
       " 'https://twitter.com/be',\n",
       " 'https://twitter.com/bs',\n",
       " 'https://twitter.com/ca',\n",
       " 'https://twitter.com/ch',\n",
       " 'https://twitter.com/co',\n",
       " 'https://twitter.com/da',\n",
       " 'https://twitter.com/do',\n",
       " 'https://twitter.com/dr',\n",
       " 'https://twitter.com/du',\n",
       " 'https://twitter.com/dw',\n",
       " 'https://twitter.com/fi',\n",
       " 'https://twitter.com/fl',\n",
       " 'https://twitter.com/gi',\n",
       " 'https://twitter.com/gl',\n",
       " 'https://twitter.com/i/',\n",
       " 'https://twitter.com/iA',\n",
       " 'https://twitter.com/i_',\n",
       " 'https://twitter.com/it',\n",
       " 'https://twitter.com/ka',\n",
       " 'https://twitter.com/ki',\n",
       " 'https://twitter.com/li',\n",
       " 'https://twitter.com/ma',\n",
       " 'https://twitter.com/me',\n",
       " 'https://twitter.com/mi',\n",
       " 'https://twitter.com/ml',\n",
       " 'https://twitter.com/mo',\n",
       " 'https://twitter.com/mu',\n",
       " 'https://twitter.com/nc',\n",
       " 'https://twitter.com/ne',\n",
       " 'https://twitter.com/ni',\n",
       " 'https://twitter.com/ny',\n",
       " 'https://twitter.com/oc',\n",
       " 'https://twitter.com/of',\n",
       " 'https://twitter.com/on',\n",
       " 'https://twitter.com/pb',\n",
       " 'https://twitter.com/pj',\n",
       " 'https://twitter.com/po',\n",
       " 'https://twitter.com/pr',\n",
       " 'https://twitter.com/pu',\n",
       " 'https://twitter.com/ra',\n",
       " 'https://twitter.com/re',\n",
       " 'https://twitter.com/ri',\n",
       " 'https://twitter.com/ro',\n",
       " 'https://twitter.com/rs',\n",
       " 'https://twitter.com/sa',\n",
       " 'https://twitter.com/sc',\n",
       " 'https://twitter.com/sh',\n",
       " 'https://twitter.com/sk',\n",
       " 'https://twitter.com/so',\n",
       " 'https://twitter.com/sp',\n",
       " 'https://twitter.com/ss',\n",
       " 'https://twitter.com/su',\n",
       " 'https://twitter.com/ta',\n",
       " 'https://twitter.com/th',\n",
       " 'https://twitter.com/tu',\n",
       " 'https://twitter.com/um',\n",
       " 'https://twitter.com/vj',\n",
       " 'https://twitter.com/vm',\n",
       " 'https://twitter.com/wh',\n",
       " 'https://twitter.com/x_',\n",
       " 'https://twitter.com/yo',\n",
       " 'https://twitter.com/yy',\n",
       " 'https://txdshs.maps.ar',\n",
       " 'https://uk-business-ne',\n",
       " 'https://us02web.zoom.u',\n",
       " 'https://wacotrib.com/n',\n",
       " 'https://waterfordwhisp',\n",
       " 'https://watsupamericas',\n",
       " 'https://wdet.org/posts',\n",
       " 'https://web.mhanet.com',\n",
       " 'https://wqth.wordpress',\n",
       " 'https://www.1011now.co',\n",
       " 'https://www.6sqft.com/',\n",
       " 'https://www.abc.net.au',\n",
       " 'https://www.acpjournal',\n",
       " 'https://www.ageofautis',\n",
       " 'https://www.aljazeera.',\n",
       " 'https://www.aninews.in',\n",
       " 'https://www.axios.com/',\n",
       " 'https://www.azdhs.gov/',\n",
       " 'https://www.bbc.co.uk/',\n",
       " 'https://www.bendigoadv',\n",
       " 'https://www.betootaadv',\n",
       " 'https://www.bloomberg.',\n",
       " 'https://www.brighteon.',\n",
       " 'https://www.bu.edu/ant',\n",
       " 'https://www.businessto',\n",
       " 'https://www.cbc.ca/new',\n",
       " 'https://www.cbsnews.co',\n",
       " 'https://www.cdc.gov/an',\n",
       " 'https://www.cdc.gov/co',\n",
       " 'https://www.cdc.gov/di',\n",
       " 'https://www.cdc.gov/me',\n",
       " 'https://www.cdc.gov/mm',\n",
       " 'https://www.cdc.gov/qu',\n",
       " 'https://www.cdc.gov/se',\n",
       " 'https://www.cdc.gov/tr',\n",
       " 'https://www.cddwestafr',\n",
       " 'https://www.cdph.ca.go',\n",
       " 'https://www.census.gov',\n",
       " 'https://www.civilaviat',\n",
       " 'https://www.clinicalmi',\n",
       " 'https://www.cms.gov/ne',\n",
       " 'https://www.cnbc.com/a',\n",
       " 'https://www.copcov.org',\n",
       " 'https://www.dailyitem.',\n",
       " 'https://www.doh.wa.gov',\n",
       " 'https://www.duffelblog',\n",
       " 'https://www.eastvalley',\n",
       " 'https://www.ed.ac.uk/u',\n",
       " 'https://www.epochtimes',\n",
       " 'https://www.eventbrite',\n",
       " 'https://www.facebook.c',\n",
       " 'https://www.factchecke',\n",
       " 'https://www.fox5atlant',\n",
       " 'https://www.foxnews.co',\n",
       " 'https://www.google.com',\n",
       " 'https://www.gossipcop.',\n",
       " 'https://www.health.gov',\n",
       " 'https://www.hhmi.org/n',\n",
       " 'https://www.hindustant',\n",
       " 'https://www.houstonchr',\n",
       " 'https://www.icmr.gov.i',\n",
       " 'https://www.imperial.a',\n",
       " 'https://www.indiatvnew',\n",
       " 'https://www.journalofh',\n",
       " 'https://www.journalofi',\n",
       " 'https://www.latimes.co',\n",
       " 'https://www.mdedge.com',\n",
       " 'https://www.medpagetod',\n",
       " 'https://www.medrxiv.or',\n",
       " 'https://www.medscape.c',\n",
       " 'https://www.mha.gov.in',\n",
       " 'https://www.modernatx.',\n",
       " 'https://www.mohfw.gov.',\n",
       " 'https://www.nature.com',\n",
       " 'https://www.nbcnews.co',\n",
       " 'https://www.nejm.org/d',\n",
       " 'https://www.newsweek.c',\n",
       " 'https://www.nih.gov/ne',\n",
       " 'https://www.npr.org/se',\n",
       " 'https://www.nytimes.co',\n",
       " 'https://www.oregonlive',\n",
       " 'https://www.perchcowor',\n",
       " 'https://www.pib.gov.in',\n",
       " 'https://www.pnas.org/c',\n",
       " 'https://www.politico.c',\n",
       " 'https://www.politifact',\n",
       " 'https://www.poynter.or',\n",
       " 'https://www.pscp.tv/w/',\n",
       " 'https://www.publicheal',\n",
       " 'https://www.recoverytr',\n",
       " 'https://www.sciencedir',\n",
       " 'https://www.scmp.com/y',\n",
       " 'https://www.sfchronicl',\n",
       " 'https://www.sltrib.com',\n",
       " 'https://www.standard.c',\n",
       " 'https://www.statnews.c',\n",
       " 'https://www.theatlanti',\n",
       " 'https://www.thebeavert',\n",
       " 'https://www.thedailyma',\n",
       " 'https://www.theguardia',\n",
       " 'https://www.thelancet.',\n",
       " 'https://www.thespoof.c',\n",
       " 'https://www.thip.media',\n",
       " 'https://www.transport.',\n",
       " 'https://www.usatoday.c',\n",
       " 'https://www.vice.com/e',\n",
       " 'https://www.vox.com/20',\n",
       " 'https://www.vox.com/id',\n",
       " 'https://www.wandtv.com',\n",
       " 'https://www.washington',\n",
       " 'https://www.wbhealth.g',\n",
       " 'https://www.who.int/em',\n",
       " 'https://www.who.int/he',\n",
       " 'https://www.who.int/ne',\n",
       " 'https://www.wionews.co',\n",
       " 'https://www.wnd.com/20',\n",
       " 'https://www.worldomete',\n",
       " 'https://www.wsj.com/ar',\n",
       " 'https://www.youtube.co',\n",
       " 'https://www1.nyc.gov/s',\n",
       " 'https://zeenews.india.',\n",
       " 'https:…',\n",
       " 'https…',\n",
       " 'http…'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred=clf.predict(Validation_ngrams)\n",
    "# f1_score(df_validation[\"label\"],y_pred,average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_test=clf.predict(Test_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_test=pd.DataFrame(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans=pd.DataFrame(df_test[\"id\"])\n",
    "# ans[\"label\"]=y_pred_test\n",
    "# ans.to_csv(\"answer9349valid.txt\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count=0\n",
    "# string=\"\"\n",
    "# for i in range(len(ans_sudhir.label)):\n",
    "#     if not((ans_sudhir.label[i]==ans.label[i]) and (ans.label[i] ==ans_MLP.label[i])):\n",
    "#         print(\"*************\")\n",
    "#         print(ans.id[i],ans_sudhir.label[i],ans.label[i],ans_MLP.label[i])\n",
    "#         print(df_test.tweet_original[i])\n",
    "#         print(\"*************\")\n",
    "# #         string+=\"\\n\"+\"\\n\" \"*************\"+\"\\n \"+str(ans.id[i])+\" Sudhir:\"+str(ans_sudhir.label[i])+\" Navneet:\"+ans.label[i]+\"\\n\"+df_test.tweet_original[i]\n",
    "#         count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file=open(\"mismatch.txt\",\"w\")\n",
    "# file.write(string)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9316940249105621"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_MLP=clf2.predict(Test_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_MLP=pd.DataFrame(df_test[\"id\"])\n",
    "ans_MLP[\"label\"]=y_pred_test_MLP\n",
    "# ans.to_csv(\"answer9349valid.txt\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>2136</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>2137</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>2138</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>2139</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>2140</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2140 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id label\n",
       "0        1  real\n",
       "1        2  fake\n",
       "2        3  fake\n",
       "3        4  real\n",
       "4        5  fake\n",
       "...    ...   ...\n",
       "2135  2136  real\n",
       "2136  2137  fake\n",
       "2137  2138  real\n",
       "2138  2139  real\n",
       "2139  2140  real\n",
       "\n",
       "[2140 rows x 2 columns]"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Jun 23 13:54:19 2020\n",
    "\n",
    "@author: suranjana\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from pysbd.utils import PySBDFactory\n",
    "import urllib\n",
    "import requests, re, spacy\n",
    "from fake_useragent import UserAgent\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import csv\n",
    "import preprocessor as p\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from googletrans import Translator\n",
    "\n",
    "translator = Translator()\n",
    "ua = UserAgent()\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# f = open('CommonWords.txt')\n",
    "# commonEngWords = f.read().splitlines()\n",
    "# f.close()\n",
    "popular_links = [\n",
    "        \"nytimes\", \"wsj\", \"huffpost\", \"washingtonpost\",\"time\",\"republicworld\",\n",
    "        \"latimes\", \"reuters\", \"abcnews\", \"usatoday\",\n",
    "        \"bloomberg\", \"nbcnews\", \"dailymail\", \"theguardian\",\n",
    "        \"thesun\", \"mirror\", \"telegraph\", \"bbc\",\n",
    "        \"thestar\", \"theglobeandmail\", \"forbes\",\n",
    "        \"cnbc\", \"chinadaily\", \"nypost\", \"usnews\",\n",
    "        \"timesofindia\", \"thehindu\", \"hindustantimes\",\n",
    "        \"cbsnews\", \"sfgate\", \"thehill\", \"thedailybeast\",\n",
    "        \"newsweek\", \"theatlantic\", \"nzherald\", \"vanguardngr\",\n",
    "        \"dailysun\", \"thejakartapost\", \"thestar\",\n",
    "        \"straitstimes\", \"bangkokpost\", \"japantimes\",\n",
    "        \"thedailystar\", \"scmp\", \"yahoo.com/news\", \"news.google\"\n",
    "        ]\n",
    "\n",
    "\n",
    "def levenshtein_ratio_and_distance(s, t, ratio_calc = False):\n",
    "    \"\"\" levenshtein_ratio_and_distance:\n",
    "        Calculates levenshtein distance between two strings.\n",
    "        If ratio_calc = True, the function computes the\n",
    "        levenshtein distance ratio of similarity between two strings\n",
    "        For all i and j, distance[i,j] will contain the Levenshtein\n",
    "        distance between the first i characters of s and the\n",
    "        first j characters of t\n",
    "    \"\"\"\n",
    "    # Initialize matrix of zeros\n",
    "    rows = len(s)+1\n",
    "    cols = len(t)+1\n",
    "    distance = np.zeros((rows,cols),dtype = int)\n",
    "\n",
    "    # Populate matrix of zeros with the indeces of each character of both strings\n",
    "    for i in range(1, rows):\n",
    "        for k in range(1,cols):\n",
    "            distance[i][0] = i\n",
    "            distance[0][k] = k\n",
    "\n",
    "    # Iterate over the matrix to compute the cost of deletions,insertions and/or substitutions    \n",
    "    for col in range(1, cols):\n",
    "        for row in range(1, rows):\n",
    "            if s[row-1] == t[col-1]:\n",
    "                cost = 0 # If the characters are the same in the two strings in a given position [i,j] then the cost is 0\n",
    "            else:\n",
    "                # In order to align the results with those of the Python Levenshtein package, if we choose to calculate the ratio\n",
    "                # the cost of a substitution is 2. If we calculate just distance, then the cost of a substitution is 1.\n",
    "                if ratio_calc == True:\n",
    "                    cost = 2\n",
    "                else:\n",
    "                    cost = 1\n",
    "            distance[row][col] = min(distance[row-1][col] + 1,      # Cost of deletions\n",
    "                                 distance[row][col-1] + 1,          # Cost of insertions\n",
    "                                 distance[row-1][col-1] + cost)     # Cost of substitutions\n",
    "    if ratio_calc == True:\n",
    "        # Computation of the Levenshtein Distance Ratio\n",
    "        Ratio = ((len(s)+len(t)) - distance[row][col]) / (len(s)+len(t))\n",
    "        return Ratio\n",
    "    else:\n",
    "        # print(distance) # Uncomment if you want to see the matrix showing how the algorithm computes the cost of deletions,\n",
    "        # insertions and/or substitutions\n",
    "        # This is the minimum number of edits needed to convert string a to string b\n",
    "        return \"The strings are {} edits away\".format(distance[row][col])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_search_result(query, number_result = 20):\n",
    "    query = urllib.parse.quote_plus(query) # Format into URL encoding\n",
    "    \n",
    "    \n",
    "    google_url = \"https://www.google.com/search?q=\" + query + \"&num=\" + str(number_result)\n",
    "    response = requests.get(google_url, {\"User-Agent\": ua.random})\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    result_div = soup.find_all('div', attrs = {'class': 'ZINbbc'})\n",
    "    \n",
    "    links = []\n",
    "    titles = []\n",
    "    descriptions = []\n",
    "    for r in result_div:\n",
    "        # Checks if each element is present, else, raise exception\n",
    "        try:\n",
    "            link = r.find('a', href = True)\n",
    "            title = r.find('div', attrs={'class':'vvjwJb'}).get_text()\n",
    "            description = r.find('div', attrs={'class':'s3v9rd'}).get_text()\n",
    "            \n",
    "            # Check to make sure everything is present before appending\n",
    "            if link != '' and title != '' and description != '': \n",
    "                links.append(link['href'])\n",
    "                titles.append(title)\n",
    "                descriptions.append(description)\n",
    "        # Next loop if one element is not present\n",
    "        except:\n",
    "            continue\n",
    "    return links, titles, descriptions\n",
    "\n",
    " \n",
    "def clean_links(links, titles, descriptions):\n",
    "    to_remove = []\n",
    "    clean_links = []\n",
    "    for i, l in enumerate(links):\n",
    "        clean = re.search('\\/url\\?q\\=(.*)\\&sa',l)\n",
    "    \n",
    "        # Anything that doesn't fit the above pattern will be removed\n",
    "        if clean is None:\n",
    "            to_remove.append(i)\n",
    "            continue\n",
    "        clean_links.append(clean.group(1))\n",
    "    \n",
    "    # Remove the corresponding titles & descriptions\n",
    "    for x in to_remove:\n",
    "        del titles[x]\n",
    "        del descriptions[x]\n",
    "    return clean_links, titles, descriptions\n",
    "\n",
    "\n",
    "def filter_links(links, titles, descriptions):\n",
    "    to_remove = []\n",
    "    for i, l in enumerate(links):\n",
    "        if not any(a in l for a in popular_links):\n",
    "            to_remove.append(i)\n",
    "            continue\n",
    "    \n",
    "    # Remove the corresponding titles & descriptions\n",
    "    links = [l for i,l in enumerate(links) if i not in to_remove]\n",
    "    titles = [t for i,t in enumerate(titles) if i not in to_remove]\n",
    "    links = [l for i,d in enumerate(descriptions) if i not in to_remove]\n",
    "    return links, titles, descriptions\n",
    "    \n",
    "\n",
    "def valid_links(links):\n",
    "    no_link = 0\n",
    "    for link in links:\n",
    "        if any(implink in link for implink in popular_links):\n",
    "            no_link = no_link+1\n",
    "    return no_link/len(links)\n",
    "\n",
    "\n",
    "def split_sentence(text):\n",
    "    nlp = spacy.blank('en')\n",
    "    nlp.add_pipe(PySBDFactory(nlp))\n",
    "    doc = nlp(text)\n",
    "    return([sent.text for sent in doc.sents if sent.text.isspace()==False])\n",
    "\n",
    "\n",
    "def valid_description(query, descriptions):\n",
    "    temp_query = preprocessing(query)\n",
    "    sentences = split_sentence(temp_query)\n",
    "    score = []\n",
    "    for q in query:\n",
    "        temp = [levenshtein_ratio_and_distance(q, sent,ratio_calc = True) for sent in sentences]\n",
    "        score.append(max(temp))\n",
    "    return sum(score)/len(score)\n",
    "\n",
    "\n",
    "def preprocessing(text):\n",
    "    p.set_options(p.OPT.URL, p.OPT.RESERVED, p.OPT.EMOJI, p.OPT.SMILEY)\n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())    \n",
    "    text = p.clean(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = text.lower().replace('[^\\w\\s]',' ').replace('\\s\\s+', ' ').replace('@','').replace('#','. ').replace('&amp;', 'and')\n",
    "    return text\n",
    "\n",
    "\n",
    "def translate_text(text):\n",
    "    result = translator.translate('Mitä sinä teet')\n",
    "    return result.text\n",
    "\n",
    "    \n",
    "# if __name__ == \"__main__\":\n",
    "#     query = \"'trade war'\"\n",
    "#     threshold = 0.3\n",
    "    tweets = []\n",
    "    clean_tweets = []\n",
    "    labels = []\n",
    "    with open('en_dataset.csv', 'rt') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            if line_count > 0:\n",
    "                tweets.append(row[2])\n",
    "                clean_tweets.append(preprocessing(row[2]))\n",
    "                labels.append(row[3])\n",
    "            line_count += 1\n",
    "#     score = []\n",
    "#     for query in tweets:\n",
    "#         links, titles, descriptions = get_search_result(query)\n",
    "#         links, titles, descriptions = filter_links(links, titles, descriptions)\n",
    "#         #descriptions = [preprocessing(desc) for desc in descriptions]\n",
    "#         if len(titles)>0:\n",
    "#             titles = [preprocessing(title.lower()) for title in titles]\n",
    "#             desc_score = valid_description(query, titles)\n",
    "#             score.append(desc_score)\n",
    "#         else:\n",
    "#             score.append(0)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 533/6324 [07:52<1:25:32,  1.13it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-962cc3a64ed2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtweet_original\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m96\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mlinks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescriptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_search_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mlinks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescriptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_links\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescriptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#descriptions = [preprocessing(desc) for desc in descriptions]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-0950060d36ef>\u001b[0m in \u001b[0;36mget_search_result\u001b[0;34m(query, number_result)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mgoogle_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://www.google.com/search?q=\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"&num=\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgoogle_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mua\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"html.parser\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m             httplib_response = self._make_request(conn, method, url,\n\u001b[0m\u001b[1;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1345\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "score=[]\n",
    "for query in tqdm(df_training.tweet_original[96:]):\n",
    "    links, titles, descriptions = get_search_result(query)\n",
    "    links, titles, descriptions = filter_links(links, titles, descriptions)\n",
    "    #descriptions = [preprocessing(desc) for desc in descriptions]\n",
    "\n",
    "    if len(titles)>0:\n",
    "        titles = [preprocessing(title.lower()) for title in titles]\n",
    "        desc_score = valid_description(query, titles)\n",
    "        score.append(desc_score)\n",
    "    else:\n",
    "        score.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-7ff4f5f4210d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5135\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'label'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0125479261066574\n",
      "1 0.016719866241070046\n",
      "2 0.015267175572519082\n",
      "3 0.010056925996204944\n",
      "4 0.009802458078320187\n",
      "5 0.010391634734039156\n",
      "6 0\n",
      "7 0.019974635383639836\n",
      "8 0.03090909090909085\n",
      "9 0\n",
      "10 0\n",
      "11 0.011405901314158228\n",
      "12 0\n",
      "13 0.011572742955721709\n",
      "14 0\n",
      "15 0.0060990099009901036\n",
      "16 0.012350119904076693\n",
      "17 0.007973311092577129\n",
      "18 0.012672176308539935\n",
      "19 0\n",
      "20 0\n",
      "21 0\n",
      "22 0.01397646069777217\n",
      "23 0.01258414617392501\n",
      "24 0.017663639210773564\n",
      "25 0.01753312945973494\n",
      "26 0\n",
      "27 0\n",
      "28 0.010941331824184051\n",
      "29 0.011924119241192426\n",
      "30 0.008901651112706379\n",
      "31 0.018849206349206324\n",
      "32 0.010223478037503184\n",
      "33 0.025717566016073442\n",
      "34 0\n",
      "35 0.016246684350132608\n",
      "36 0\n",
      "37 0.03361344537815128\n",
      "38 0.023953823953823936\n",
      "39 0.021733073279465005\n",
      "40 0\n",
      "41 0.01848739495798316\n",
      "42 0.012285927029039502\n",
      "43 0.01005544980551189\n",
      "44 0.01993769470404981\n",
      "45 0.015142337976983628\n",
      "46 0.018779342723004706\n",
      "47 0.01143168209036472\n",
      "48 0.014456316781898201\n",
      "49 0.013580194846273864\n",
      "50 0.00981402986214539\n",
      "51 0.00919305413687438\n",
      "52 0.028780743066457372\n",
      "53 0.01309935739001482\n",
      "54 0.02481572481572483\n",
      "55 0.015240833932422718\n",
      "56 0.01876955161626692\n",
      "57 0.017009106645593432\n",
      "58 0.011296800103640333\n",
      "59 0.03672580143168379\n",
      "60 0\n",
      "61 0.016241610738255044\n",
      "62 0.037066881547139385\n",
      "63 0.013215859030837036\n",
      "64 0.02277992277992275\n",
      "65 0.028846153846153848\n",
      "66 0.015007215007214962\n",
      "67 0.022130532633158274\n",
      "68 0.009154228855721414\n",
      "69 0.03511904761904761\n",
      "70 0.01661807580174926\n",
      "71 0.006607604282022871\n",
      "72 0.010173512676679333\n",
      "73 0.022209002577830674\n",
      "74 0.03325238184195778\n",
      "75 0.017444114226644207\n",
      "76 0\n",
      "77 0\n",
      "78 0.0168771777003484\n",
      "79 0.0186353631694791\n",
      "80 0.008504696623508511\n",
      "81 0\n",
      "82 0.013955984970477746\n",
      "83 0.027115474520804136\n",
      "84 0.014555468135326504\n",
      "85 0.014554411106135234\n",
      "86 0.010421702927746414\n",
      "87 0.007140166713066852\n",
      "88 0.010403417180825844\n",
      "89 0.006303915063039125\n",
      "90 0.052455357142857144\n",
      "91 0.007131925313743475\n",
      "92 0.028324154209284007\n",
      "93 0.022700119474312986\n",
      "94 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(score[0:95])):\n",
    "#     print(i,score[i],df_training.label[i],s[i])\n",
    "        print(i,score[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis=score2+score+score3\n",
    "# len(score3)+len(score2)+len(score)\n",
    "# len(lis)\n",
    "# len(score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file=open(\"score_train_95\",'wb')\n",
    "pickle.dump(score,file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6420"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "file=open(\"score_train\",'rb')\n",
    "s=pickle.load(file)\n",
    "file.close()\n",
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lis=[]\n",
    "for i in lis:\n",
    "        train_lis.append([i])\n",
    "valid_lis=[]\n",
    "for i in score:\n",
    "        valid_lis.append([i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "csr_TrainFeature_without_ngram=csr_matrix(Train_f)\n",
    "csr_ValidFeature_without_ngram=csr_matrix(Validation_f)\n",
    "TrainFeatureFinal=hstack([Train_ngrams,csr_TrainFeature_without_ngram])\n",
    "ValidFeatureFinal=hstack([Validation_ngrams,csr_ValidFeature_without_ngram])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "clf = make_pipeline(StandardScaler(with_mean=False), SVC(gamma='auto',kernel=\"sigmoid\"))\n",
    "clf.fit(TrainFeatureFinal,df_training[\"label\"])\n",
    "y_pred=clf.predict(ValidFeatureFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9223158467450243"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred,df_validation[\"label\"],average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Accuracy: 0.9247663551401869\n",
      "-----------------\n",
      "\n",
      "For the Positive CLass, Label:4\n",
      "-----------------\n",
      "Precision: 0.9205357142857142\n",
      "-----------------\n",
      "Recall: 0.9347234814143246\n",
      "-----------------\n",
      "F1 Score: 0.9275753486279802\n",
      "\n",
      "For the Negative CLass, Label:0\n",
      "-----------------\n",
      "Precision: 0.9294117647058824\n",
      "-----------------\n",
      "Recall: 0.914175506268081\n",
      "-----------------\n",
      "F1 Score: 0.921730675741371\n",
      "\n",
      "--------\n",
      "Macro Average F1 0.9246530121846757\n",
      "-----------------\n",
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                 948                  89\n",
      "Actual Positive                  72                1031\n"
     ]
    }
   ],
   "source": [
    "func_Eval(y_pred,df_validation[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
