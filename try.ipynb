{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "import preprocessor as p\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "import emoji\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_Eval(Y_Actual,Y_pred):\n",
    "\n",
    "    TrueNegative=0\n",
    "    TruePositive=0\n",
    "    FalsePositive=0\n",
    "    FalseNegative=0\n",
    "    for i in range(len(Y_pred)):\n",
    "        #if the actual class is negative\n",
    "        if(Y_Actual[i]==\"fake\"):\n",
    "            \n",
    "            #if the predicited class is negative\n",
    "            if(Y_pred[i]==\"fake\"):\n",
    "                TrueNegative+=1\n",
    "                \n",
    "            #if the predicted class is positive\n",
    "            else:\n",
    "                FalsePositive+=1\n",
    "                \n",
    "        #if the actual class is positive\n",
    "        else:\n",
    "            #if the predicited class is positive\n",
    "            if(Y_pred[i]==\"real\"):\n",
    "                TruePositive+=1\n",
    "                \n",
    "            #if the predicited class is negative\n",
    "            else:\n",
    "                FalseNegative+=1\n",
    "\n",
    "    Confusion_Matrix=[[TrueNegative,FalsePositive],[FalseNegative,TruePositive]]\n",
    "    \n",
    "    Confusion_Matrix=pd.DataFrame(Confusion_Matrix,columns=['Predicted Negative','Predicted Positive'])\n",
    "    \n",
    "    Confusion_Matrix.rename(index={0: \"Actual Negative\", 1: \"Actual Positive\"},inplace=True)\n",
    "    \n",
    "    MyPrecision=TruePositive/(TruePositive+FalsePositive)\n",
    "\n",
    "    MyRecall=TruePositive/(TruePositive+FalseNegative)\n",
    "    \n",
    "    MyAccuracy=(TruePositive+TrueNegative)/(TruePositive+TrueNegative+FalseNegative+FalsePositive)\n",
    "    \n",
    "    MyF1score= 2*(MyPrecision*MyRecall)/(MyPrecision+MyRecall)\n",
    "    \n",
    "    MyPrecisionZero=TrueNegative/(TrueNegative+FalseNegative)\n",
    "\n",
    "    MyRecallZero=TrueNegative/(TrueNegative+FalsePositive)\n",
    "    \n",
    "    \n",
    "    MyF1scoreZero= 2*(MyPrecisionZero*MyRecallZero)/(MyPrecisionZero+MyRecallZero)\n",
    "\n",
    "    \n",
    "    print(\"-----------------\")\n",
    "    print(\"Accuracy:\",MyAccuracy)\n",
    "    print(\"-----------------\")\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(\"For the Positive CLass, Label:4\")\n",
    "    print(\"-----------------\")\n",
    "    print(\"Precision:\",MyPrecision)\n",
    "\n",
    "    print(\"-----------------\")\n",
    "    print(\"Recall:\",MyRecall)\n",
    "\n",
    "    print(\"-----------------\")\n",
    "    print(\"F1 Score:\",MyF1score)\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(\"For the Negative CLass, Label:0\")\n",
    "\n",
    "    print(\"-----------------\")\n",
    "    print(\"Precision:\",MyPrecisionZero)\n",
    "\n",
    "    print(\"-----------------\")\n",
    "    print(\"Recall:\",MyRecallZero)\n",
    "\n",
    "    print(\"-----------------\")\n",
    "    print(\"F1 Score:\",MyF1scoreZero)\n",
    "\n",
    "    print()\n",
    "    print(\"--------\")\n",
    "    print(\"Macro Average F1\",(MyF1score+MyF1scoreZero)/2)\n",
    "    print(\"-----------------\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(Confusion_Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_caller(Tweets_List):\n",
    "    stop_words_list=stopwords.words('english')\n",
    "    for i in (range(len(Tweets_List))):\n",
    "        Tweets_List[i]=preprocess_text(Tweets_List[i],stop_words_list=stop_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(tweet, flag_stemm=True, flag_lemm=False, stop_words_list=None):\n",
    "#     print(tweet)\n",
    "    tweet=emoji.demojize(tweet)\n",
    "    tweet=tweet.replace(\":\",\" \")\n",
    "#     print(tweet)\n",
    "\n",
    "    ## clean (convert to lowercase and remove punctuations and characters and then strip)\n",
    "    tweet = re.sub(r'[^\\w\\s]', '', str(tweet).lower().strip())\n",
    "    ## Tokenize (convert from string to list) and remove the stop words\n",
    "#     print(tweet)\n",
    "\n",
    "    tokenize_tweet = tweet.split()\n",
    "\n",
    "    if stop_words_list is not None:\n",
    "        tokenize_tweet = [word for word in tokenize_tweet if word not in stop_words_list]\n",
    "\n",
    "\n",
    "    ## Stemming (remove -ing, -ly, ...)\n",
    "    if flag_stemm == True:\n",
    "        ps = nltk.stem.porter.PorterStemmer()\n",
    "        tokenize_tweet = [ps.stem(word) for word in tokenize_tweet]\n",
    "\n",
    "    ## Lemmatisation (convert the word into root word)\n",
    "    if flag_lemm == True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        tokenize_tweet = [lem.lemmatize(word) for word in tokenize_tweet]\n",
    "#     print(tokenize_tweet)\n",
    "    ## back to string from list\n",
    "    tweet = \" \".join(tokenize_tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training=pd.DataFrame(pd.read_csv(\"Constraint_English_Train - Sheet1.csv\"))\n",
    "df_training.drop(columns=\"id\",inplace=True)\n",
    "df_training\n",
    "df_training['tweet_original']=df_training['tweet']\n",
    "preprocess_text_caller(df_training['tweet'])\n",
    "\n",
    "\n",
    "\n",
    "# df_testing=pd.DataFrame(pd.read_csv(\"testset-levela.tsv\",sep=\"\\t\"))\n",
    "# df_testing['tweet_original']=df_testing['tweet']\n",
    "# preprocess_text_caller(df_testing['tweet'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# ngram_range parameter (1,2) means that unigram and bigram will be taken\n",
    "# Count Vecotrizer automatically preprocess the tweets\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,4),min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_ngrams=vectorizer.fit_transform(df_training.tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation=pd.DataFrame(pd.read_csv(\"Constraint_English_Val - Sheet1.csv\"))\n",
    "df_validation.drop(columns=\"id\",inplace=True)\n",
    "df_validation\n",
    "df_validation['tweet_original']=df_validation['tweet']\n",
    "preprocess_text_caller(df_validation['tweet'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Validation_ngrams=vectorizer.transform(df_validation.tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2140x5791 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 40205 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Validation_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "clf.fit(Train_ngrams,df_training[\"label\"])\n",
    "y_pred=clf.predict(Validation_ngrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.918082612536882"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred,df_validation[\"label\"],average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9182242990654206"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred,df_validation[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "clf = make_pipeline(StandardScaler(with_mean=False), SVC(gamma='auto'))\n",
    "clf.fit(Train_ngrams,df_training[\"label\"])\n",
    "y_pred=clf.predict(Validation_ngrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9182242990654206"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred,df_validation[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Accuracy: 0.9182242990654206\n",
      "-----------------\n",
      "\n",
      "For the Positive CLass, Label:4\n",
      "-----------------\n",
      "Precision: 0.9223214285714286\n",
      "-----------------\n",
      "Recall: 0.9214986619090099\n",
      "-----------------\n",
      "F1 Score: 0.9219098616688978\n",
      "\n",
      "For the Negative CLass, Label:0\n",
      "-----------------\n",
      "Precision: 0.9137254901960784\n",
      "-----------------\n",
      "Recall: 0.914622178606477\n",
      "-----------------\n",
      "F1 Score: 0.91417361451692\n",
      "\n",
      "--------\n",
      "Macro Average F1 0.9180417380929089\n",
      "-----------------\n",
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                 932                  87\n",
      "Actual Positive                  88                1033\n"
     ]
    }
   ],
   "source": [
    "func_Eval(y_pred,df_validation[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
